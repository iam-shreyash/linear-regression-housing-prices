# ğŸ  Housing Price Prediction with Linear Regression  

## ğŸ“Œ Objective  
Build a simple **Linear Regression Model** to predict **housing prices** using **2 features** (`RM` and `LSTAT`) from the dataset.  

---

## ğŸ“‚ Contents  
- `Housing Data.csv` â†’ dataset used  
- `linear-regression-housing-prices.ipynb` â†’ Jupyter notebook with code  
- `images/` â†’ visualizations (scatter plots, regression line, etc.)  
- `README.md` â†’ project story  

---

## âš™ï¸ Tools & Libraries  
- Python 3.x  
- pandas  
- scikit-learn  
- matplotlib, seaborn  

---

## ğŸš€ Steps  
1. Loaded dataset (`Housing Data.csv`)  
2. Selected 2 features:  
   - **RM** â†’ Average number of rooms  
   - **LSTAT** â†’ % lower status population  
3. Handled missing values (`LSTAT` had 20 missing values â†’ dropped)  
4. Split data into **train** and **test** using `train_test_split`  
5. Trained a **Linear Regression Model** using scikit-learn  
6. Evaluated with **RÂ², MAE, RMSE**  
7. Visualized **Actual vs Predicted Prices** and **Regression Line**  

---

## ğŸ“Š Results  
- **RÂ² Score**: ~0.66  
- **MAE**: ~3.7  
- **RMSE**: ~4.8  
- Positive correlation between **RM** (rooms) and **MEDV** (price)  
- Negative correlation between **LSTAT** (lower status %) and **MEDV**  

---

## ğŸ–¼ Visualizations  
### 1. Actual vs Predicted Prices  
![Actual vs Predicted](images/actual_vs_predicted.png)  

### 2. Regression Line (RM vs MEDV)  
![Regression Line](images/regression_line.png)  

---

## ğŸ“ Conclusion  
Linear Regression with just **2 features** gives a **decent prediction accuracy** (RÂ² â‰ˆ 0.66).  
Adding more features or advanced models (e.g., Random Forest, XGBoost) can further improve performance.  
